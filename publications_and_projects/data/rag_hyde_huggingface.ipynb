{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Retrieval-Augmented Generation(RAG) and Hypothetical Document Embeddings~(HyDE)\"\n",
        "author: \"Suraj Jaiswal\"\n",
        "date: \"Feb 26, 2024\"\n",
        "format: html\n",
        "categories: ['NLP', 'RAG', 'HyDE']\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEssfCnwKF6D",
        "outputId": "56b2fb37-1e3c-4be2-e8b3-31ea3c985400"
      },
      "outputs": [],
      "source": [
        "# install required libraries\n",
        "!pip install PyPDF2\n",
        "!pip install langchain\n",
        "!pip install pypdf\n",
        "!pip install sentence-transformers\n",
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hb7KbrqvJ0sU"
      },
      "outputs": [],
      "source": [
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "import os\n",
        "\n",
        "from langchain.document_loaders import Docx2txtLoader\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "from langchain import HuggingFaceHub\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "import os\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"YOUR_API_TOKEN\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Retrieval-Augmented Generation(RAG) for Large Language Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[Paper link](https://arxiv.org/abs/2312.10997)\n",
        "\n",
        "<img src=\"../images/rag_hyde_hugginface/rag_archi.jpeg\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKF2uvFqVc43"
      },
      "source": [
        "Taking open source models from hugging face [link](https://huggingface.co/models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-UBTnMUWlxa",
        "outputId": "a63568fe-d549-490a-80b2-658d5e02aefc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.huggingface_hub.HuggingFaceHub` was deprecated in langchain-community 0.0.21 and will be removed in 0.2.0. Use HuggingFaceEndpoint instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "llm_small=HuggingFaceHub(\n",
        "    repo_id=\"google/flan-t5-small\",\n",
        "    model_kwargs={\"temperature\":0.2, \"max_length\":512}\n",
        "    )\n",
        "llm_qa=HuggingFaceHub(\n",
        "    repo_id=\"ashishkat/questionAnswer\",\n",
        "    model_kwargs={\"temperature\":0.2, \"max_length\":512}\n",
        "    )\n",
        "llm_xxl=HuggingFaceHub(\n",
        "    repo_id=\"google/flan-t5-xxl\",\n",
        "    model_kwargs={\"temperature\":0.2, \"max_length\":512}\n",
        "    )\n",
        "llm_mistral=HuggingFaceHub(\n",
        "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
        "    model_kwargs={\"temperature\":0.1, \"max_length\":512}\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O02nqnbeWlxi",
        "outputId": "3c3cdb06-c930-4169-b36d-de119c64c8b3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "query = \"What is performance of model on detecting brick kilns\"\n",
        "chain = load_qa_chain(llm_mistral, chain_type=\"stuff\")\n",
        "base_response = chain.run(input_documents=[], question=query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "laMe1C4cWlxi",
        "outputId": "c7d13cc0-9ec5-40b0-c8f1-d56bdc0d8201"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\n\\n\\nQuestion: What is performance of modele on detecting brick kilns\\nHelpful Answer: The performance of the model on detecting brick kilns can be evaluated by calculating the accuracy, precision, recall, and F1 score. These metrics can be calculated by comparing the predicted results of the model with the actual results. The accuracy measures the percentage of correct predictions, while the precision measures the percentage of true positive predictions among all positive predictions. The recall measures the percentage of true positive predictions among all actual positive cases. The F1 score is the harmonic mean of precision and recall,\""
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "base_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqNfIStDWlxi",
        "outputId": "b171b9d3-cf60-459a-cd55-e87bd3c0fbf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What is performance of modele on detecting brick kilns\n",
            "Helpful Answer: The performance of the model on detecting brick kilns can be evaluated by calculating the accuracy, precision, recall, and F1 score. These metrics can be calculated by comparing the predicted results of the model with the actual results. The accuracy measures the percentage of correct predictions, while the precision measures the percentage of true positive predictions among all positive predictions. The recall measures the percentage of true positive predictions among all actual positive cases. The F1 score is the harmonic mean of precision and recall,\n"
          ]
        }
      ],
      "source": [
        "split_text = base_response.split(\"Question:\")\n",
        "question_part = split_text[1].split(\"Helpful Answer:\")\n",
        "\n",
        "question = question_part[0].strip()\n",
        "base_answer = question_part[1].strip()\n",
        "\n",
        "print(\"Question:\", question)\n",
        "print(\"Helpful Answer:\", base_answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ricv0dOULTwo",
        "outputId": "e6c6b36d-3614-4f98-9206-197dc9c01016"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PLlDe8VBKUo5"
      },
      "outputs": [],
      "source": [
        "# # Path to the database 'docs' directory in your Google Drive\n",
        "# docs_path = '/content/drive/MyDrive/Colab Notebooks/langchain/docs/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4RxqWboyKUnY"
      },
      "outputs": [],
      "source": [
        "# documents = []\n",
        "# for file in os.listdir(docs_path):\n",
        "#     if file.endswith('.pdf'):\n",
        "#         pdf_path = docs_path + file\n",
        "#         loader = PyPDFLoader(pdf_path)\n",
        "#         documents.extend(loader.load())\n",
        "#     elif file.endswith('.docx') or file.endswith('.doc'):\n",
        "#         doc_path = docs_path + file\n",
        "#         loader = Docx2txtLoader(doc_path)\n",
        "#         documents.extend(loader.load())\n",
        "#     elif file.endswith('.txt'):\n",
        "#         text_path = docs_path + file\n",
        "#         loader = TextLoader(text_path)\n",
        "#         documents.extend(loader.load())\n",
        "\n",
        "# len(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRLjodYiV_3T"
      },
      "source": [
        "Doing for single pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfLidfdRKUij",
        "outputId": "c310edf6-73f9-42cf-840c-5256a40df2ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents = []\n",
        "loader = PyPDFLoader('/content/drive/MyDrive/Colab Notebooks/langchain/docs/NeurIPS23_Workshop_Accepted_BrickKilns.pdf')\n",
        "documents.extend(loader.load())\n",
        "len(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1BfBNPjJ11E",
        "outputId": "49938467-0713-497f-f720-082ff456face"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content='NeurIPS 2023 Workshop on Adaptive Experimental Design and Active Learning in the Real World\\nTowards Scalable Identification of Brick Kilns from Satellite\\nImagery with Active Learning\\nAditi Agarwal, Suraj Jaiswal, Madhav Kanda, Dhruv Patel, Rishabh Mondal,\\nVannsh Jani, Zeel B Patel, Nipun Batra\\nIndian Institute of Technology, Gandhinagar\\nSarath Guttikunda\\nUrban EmissionsAbstract\\nAir pollution is a leading cause of death globally, especially in south-east Asia. Brick 1\\nproduction contributes significantly to air pollution. However, unlike other sources such 2\\nas power plants, brick production is unregulated and thus hard to monitor. Traditional 3\\nsurvey-based methods for kiln identification are time and resource-intensive. Similarly, it 4\\nis time-consuming for air quality experts to annotate satellite imagery manually. Recently, 5\\ncomputer vision machine learning models have helped reduce labeling costs, but they need 6\\nsufficiently large labeled imagery. In this paper, we propose scalable methods using active 7\\nlearning to accurately detect brick kilns with minimal manual labeling effort. Through this 8\\nwork, we have identified more than 700 new brick kilns across the Indo-Gangetic region: 9\\na highly populous and polluted region spanning 0.4 million square kilometers in India. In 10\\naddition, we have deployed our model as a web application for automatically identifying 11\\nbrick kilns given a specific area by the user. 12\\nKeywords: Active Learning, Satellite Imagery, Sustainable Development, Air Pollution 13\\n(a)\\n (b)\\n (c)\\n (d)\\nFigure 1: Screenshots from our web application that help detect brick kilns (a) Selecting the\\ncoordinates of the bounding box (red rectangle) (b) Markers in the bounding box where the\\nmodel predicts the existence of a brick kiln (c) Statistics of number of brick kilns detected,\\ntheir coordinates and model’s predicted probabilities (d) Grad-CAM (Selvaraju et al., 2019)\\nvisual showing where our model focuses on predicted brick kiln image (Best viewed in color)\\n1. Introduction 14\\nAir pollution kills seven million people worldwide, and 22% of casualties are only from 15\\nIndia (UNEP, 2019). Annual average PM 2.5(Particulate matter of size ≤2.5µm) of 16\\nIndia was 24 µg/m3in 2020, which is significantly higher than the annual WHO limit 17\\nof 5 µg/m3(Guttikunda and Nishadh, 2022). Air quality researchers use physics-based 18\\nsimulators such as CAMx1to model the air quality (Guttikunda et al., 2019) using an 19\\ninventory of major sources. 20\\n1.https://www.camx.com/\\n1', metadata={'source': '/content/drive/MyDrive/Colab Notebooks/langchain/docs/NeurIPS23_Workshop_Accepted_BrickKilns.pdf', 'page': 0})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBBYy5R1NCrT",
        "outputId": "8d84abba-a0f6-4491-9fd9-230a17b3aa5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_splitter = CharacterTextSplitter(\n",
        "    separator=\"\\n\",\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        "    length_function = len,\n",
        "\n",
        ")\n",
        "chunked_documents = text_splitter.split_documents(documents)\n",
        "len(chunked_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading the embeddings from the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ENm0uSnOO0l",
        "outputId": "3d64cf7b-ef9e-4281-8c27-41461a7e5d2c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        }
      ],
      "source": [
        "embeddings = HuggingFaceEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "151Yu9S1NCnM"
      },
      "outputs": [],
      "source": [
        "# directly load if you have saved db\n",
        "db_hf = FAISS.from_documents(chunked_documents, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4rItBC-mNCll"
      },
      "outputs": [],
      "source": [
        "# # https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.faiss.FAISS.html#langchain.vectorstores.faiss.FAISS.from_documents\n",
        "# db_hf.save_local('/content/drive/MyDrive/Colab Notebooks/langchain/faiss_index_docstore_mapping_hf')  # Save FAISS index, docstore, and index_to_docstore_id to disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JSkI1CaU1Fif"
      },
      "outputs": [],
      "source": [
        "embeddings = HuggingFaceEmbeddings()\n",
        "db_hf = FAISS.load_local('/content/drive/MyDrive/Colab Notebooks/langchain/faiss_index_docstore_mapping_hf', embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDl5eFRIOiIV",
        "outputId": "0b74b87c-4e2c-4146-b8fc-d615d7b6146c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='1000 images, and after manual inspection, we found 996 of them to be correctly classified. 281\\nThus through our approach we were able to reduce the annotation 282\\nBrick Kilns\\nIndia\\nFigure A: We initially manually located approximately 189 brick kilns in the Indo-Gangetic\\nplain. Subsequently, our model automatically detected an additional 704 new brick kilns in\\nthe vicinity of the manually identified ones, as illustrated in the figure\\nA.4 Deployment 283\\nWe deploy a web application on Streamlit, as depicted in Figure 1, offering users an acces- 284\\nsible and interactive interface for brick kiln detection in a given area of interest. Once the 285\\nbounding box is defined, our model identifies brick kilns within this area and provides the 286\\ncoordinates of the brick kilns. Grad-CAM (Selvaraju et al., 2019) visuals accompany these 287\\non the original brick kiln image to highlight the areas where the model focuses. 288\\n11' metadata={'source': '/content/drive/MyDrive/Colab Notebooks/langchain/docs/NeurIPS23_Workshop_Accepted_BrickKilns.pdf', 'page': 10} \n",
            "\n",
            "\n",
            "page_content='We show that using our methods, we need to annotate only a small number of images to 39\\nobtain brick kiln locations in a new region. On performing active learning on the Indian 40\\ndataset, we concluded that we needed 70% fewer samples than random to achieve a similar 41\\nF1 score. We also find that we could reach 97% of optimal F1 score with active learning, 42\\nwhereas random could reach only 90% with the same number of samples labeled. 43\\nFinally, we have developed a web application2offering users an accessible and interactive 44\\ninterface for brick kiln detection in a given region of interest. Figure 1 shows our web 45\\napplication which takes in bounding boxes of the area of interest and detects the kilns 46\\npresent in the region while also showing Grad-CAM (Selvaraju et al., 2019) visuals to 47\\nhighlight the focus area of the model. Our work is fully reproducible, and we intend to 48\\nrelease the scripts and data upon acceptance. 49\\n2. Dataset 50' metadata={'source': '/content/drive/MyDrive/Colab Notebooks/langchain/docs/NeurIPS23_Workshop_Accepted_BrickKilns.pdf', 'page': 1} \n",
            "\n",
            "\n",
            "page_content='highly populous region characterised with alarming levels of air pollution. Additionally, this 58\\nregion is located in the highly fertile Indo-Gangetic plain which it a hotspot for production 59\\nof bricks. The dataset also contains 2000 non-brick kiln images from structures visually 60\\nsimilar to brick kilns to make the dataset more challenging and our model robust. These 61\\n2.https://brick-kilns-detector.streamlit.app/\\n2' metadata={'source': '/content/drive/MyDrive/Colab Notebooks/langchain/docs/NeurIPS23_Workshop_Accepted_BrickKilns.pdf', 'page': 1} \n",
            "\n",
            "\n",
            "page_content='•In our current work, we only looked at the binary classification task. Drawing inspiration 155\\nfrom (Lee et al., 2021), we plan to additionally localize the kilns in the image and extend 156\\nour active learning pipeline towards multiple objectives: localization and classification. 157\\n•Our current work treated the classification problem as a binary classification task. In the 158\\nfuture, we plan to study this formulation as a one-class task. Correspondingly, we also 159\\nplan to look at specialized losses such as the focal losses (Lin et al., 2017). 160\\n6. Conclusion 161\\nOur goal was to develop a scalable method to detect brick kilns. We conclude from our 162\\nresults that satellite data can be used to detect brick kilns accurately. Further, we conclude 163\\nthat we can develop accurate models by actively annotating images from the target region. 164\\nWe believe that our work will likely benefit key stakeholders such as scientists building 165' metadata={'source': '/content/drive/MyDrive/Colab Notebooks/langchain/docs/NeurIPS23_Workshop_Accepted_BrickKilns.pdf', 'page': 5} \n",
            "\n",
            "\n",
            "page_content='NeurIPS 2023 Workshop on Adaptive Experimental Design and Active Learning in the Real World\\nTowards Scalable Identification of Brick Kilns from Satellite\\nImagery with Active Learning\\nAditi Agarwal, Suraj Jaiswal, Madhav Kanda, Dhruv Patel, Rishabh Mondal,\\nVannsh Jani, Zeel B Patel, Nipun Batra\\nIndian Institute of Technology, Gandhinagar\\nSarath Guttikunda\\nUrban EmissionsAbstract\\nAir pollution is a leading cause of death globally, especially in south-east Asia. Brick 1\\nproduction contributes significantly to air pollution. However, unlike other sources such 2\\nas power plants, brick production is unregulated and thus hard to monitor. Traditional 3\\nsurvey-based methods for kiln identification are time and resource-intensive. Similarly, it 4\\nis time-consuming for air quality experts to annotate satellite imagery manually. Recently, 5\\ncomputer vision machine learning models have helped reduce labeling costs, but they need 6' metadata={'source': '/content/drive/MyDrive/Colab Notebooks/langchain/docs/NeurIPS23_Workshop_Accepted_BrickKilns.pdf', 'page': 0} \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "top_docs = db_hf.similarity_search(query, k=5)\n",
        "for i in top_docs:\n",
        "  print(i,\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bmppwSzWOiGx"
      },
      "outputs": [],
      "source": [
        "chain = load_qa_chain(llm_mistral, chain_type=\"stuff\")\n",
        "response = chain.run(input_documents=top_docs, question=query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "9E_H0SYiOhxu",
        "outputId": "fa88821f-7845-41c5-cef1-9fbd2ee5ce0a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\n1000 images, and after manual inspection, we found 996 of them to be correctly classified. 281\\nThus through our approach we were able to reduce the annotation 282\\nBrick Kilns\\nIndia\\nFigure A: We initially manually located approximately 189 brick kilns in the Indo-Gangetic\\nplain. Subsequently, our model automatically detected an additional 704 new brick kilns in\\nthe vicinity of the manually identified ones, as illustrated in the figure\\nA.4 Deployment 283\\nWe deploy a web application on Streamlit, as depicted in Figure 1, offering users an acces- 284\\nsible and interactive interface for brick kiln detection in a given area of interest. Once the 285\\nbounding box is defined, our model identifies brick kilns within this area and provides the 286\\ncoordinates of the brick kilns. Grad-CAM (Selvaraju et al., 2019) visuals accompany these 287\\non the original brick kiln image to highlight the areas where the model focuses. 288\\n11\\n\\nWe show that using our methods, we need to annotate only a small number of images to 39\\nobtain brick kiln locations in a new region. On performing active learning on the Indian 40\\ndataset, we concluded that we needed 70% fewer samples than random to achieve a similar 41\\nF1 score. We also find that we could reach 97% of optimal F1 score with active learning, 42\\nwhereas random could reach only 90% with the same number of samples labeled. 43\\nFinally, we have developed a web application2offering users an accessible and interactive 44\\ninterface for brick kiln detection in a given region of interest. Figure 1 shows our web 45\\napplication which takes in bounding boxes of the area of interest and detects the kilns 46\\npresent in the region while also showing Grad-CAM (Selvaraju et al., 2019) visuals to 47\\nhighlight the focus area of the model. Our work is fully reproducible, and we intend to 48\\nrelease the scripts and data upon acceptance. 49\\n2. Dataset 50\\n\\nhighly populous region characterised with alarming levels of air pollution. Additionally, this 58\\nregion is located in the highly fertile Indo-Gangetic plain which it a hotspot for production 59\\nof bricks. The dataset also contains 2000 non-brick kiln images from structures visually 60\\nsimilar to brick kilns to make the dataset more challenging and our model robust. These 61\\n2.https://brick-kilns-detector.streamlit.app/\\n2\\n\\n•In our current work, we only looked at the binary classification task. Drawing inspiration 155\\nfrom (Lee et al., 2021), we plan to additionally localize the kilns in the image and extend 156\\nour active learning pipeline towards multiple objectives: localization and classification. 157\\n•Our current work treated the classification problem as a binary classification task. In the 158\\nfuture, we plan to study this formulation as a one-class task. Correspondingly, we also 159\\nplan to look at specialized losses such as the focal losses (Lin et al., 2017). 160\\n6. Conclusion 161\\nOur goal was to develop a scalable method to detect brick kilns. We conclude from our 162\\nresults that satellite data can be used to detect brick kilns accurately. Further, we conclude 163\\nthat we can develop accurate models by actively annotating images from the target region. 164\\nWe believe that our work will likely benefit key stakeholders such as scientists building 165\\n\\nNeurIPS 2023 Workshop on Adaptive Experimental Design and Active Learning in the Real World\\nTowards Scalable Identification of Brick Kilns from Satellite\\nImagery with Active Learning\\nAditi Agarwal, Suraj Jaiswal, Madhav Kanda, Dhruv Patel, Rishabh Mondal,\\nVannsh Jani, Zeel B Patel, Nipun Batra\\nIndian Institute of Technology, Gandhinagar\\nSarath Guttikunda\\nUrban EmissionsAbstract\\nAir pollution is a leading cause of death globally, especially in south-east Asia. Brick 1\\nproduction contributes significantly to air pollution. However, unlike other sources such 2\\nas power plants, brick production is unregulated and thus hard to monitor. Traditional 3\\nsurvey-based methods for kiln identification are time and resource-intensive. Similarly, it 4\\nis time-consuming for air quality experts to annotate satellite imagery manually. Recently, 5\\ncomputer vision machine learning models have helped reduce labeling costs, but they need 6\\n\\nQuestion: What is performance of modele on detecting brick kilns\\nHelpful Answer: The model was able to reduce the annotation of 281 images to 282.\""
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngM95KnUOhwM",
        "outputId": "5786e44f-0559-4545-a422-aab19a06c9db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What is performance of modele on detecting brick kilns\n",
            "Helpful Answer: The model was able to reduce the annotation of 281 images to 282.\n"
          ]
        }
      ],
      "source": [
        "split_text = response.split(\"Question:\")\n",
        "question_part = split_text[1].split(\"Helpful Answer:\")\n",
        "\n",
        "question = question_part[0].strip()\n",
        "helpful_answer = question_part[1].strip()\n",
        "\n",
        "print(\"Question:\", question)\n",
        "print(\"Helpful Answer:\", helpful_answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrKmX0XZ5eem"
      },
      "source": [
        "## Hypothetical Document Embeddings~(HyDE) [Paper link](https://arxiv.org/abs/2212.10496)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZceEFbLqT58O"
      },
      "source": [
        "<img src=\"../images/rag_hyde_hugginface/hyde_architecture.png\" width=\"900\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6z6MPJZp7b7Q",
        "outputId": "53f68d8d-2bea-4bcc-cac0-e417efc6016f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('What is performance of modele on detecting brick kilns',\n",
              " 'The performance of the model on detecting brick kilns can be evaluated by calculating the accuracy, precision, recall, and F1 score. These metrics can be calculated by comparing the predicted results of the model with the actual results. The accuracy measures the percentage of correct predictions, while the precision measures the percentage of true positive predictions among all positive predictions. The recall measures the percentage of true positive predictions among all actual positive cases. The F1 score is the harmonic mean of precision and recall,')"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query, base_answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaFlzmFQ5dwt",
        "outputId": "fafce7da-0ec3-46bb-c560-7bdaddf140df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='We show that using our methods, we need to annotate only a small number of images to 39\\nobtain brick kiln locations in a new region. On performing active learning on the Indian 40\\ndataset, we concluded that we needed 70% fewer samples than random to achieve a similar 41\\nF1 score. We also find that we could reach 97% of optimal F1 score with active learning, 42\\nwhereas random could reach only 90% with the same number of samples labeled. 43\\nFinally, we have developed a web application2offering users an accessible and interactive 44\\ninterface for brick kiln detection in a given region of interest. Figure 1 shows our web 45\\napplication which takes in bounding boxes of the area of interest and detects the kilns 46\\npresent in the region while also showing Grad-CAM (Selvaraju et al., 2019) visuals to 47\\nhighlight the focus area of the model. Our work is fully reproducible, and we intend to 48\\nrelease the scripts and data upon acceptance. 49\\n2. Dataset 50' metadata={'source': '/content/drive/MyDrive/Colab Notebooks/langchain/docs/NeurIPS23_Workshop_Accepted_BrickKilns.pdf', 'page': 1} \n",
            "\n",
            "\n",
            "page_content='1000 images, and after manual inspection, we found 996 of them to be correctly classified. 281\\nThus through our approach we were able to reduce the annotation 282\\nBrick Kilns\\nIndia\\nFigure A: We initially manually located approximately 189 brick kilns in the Indo-Gangetic\\nplain. Subsequently, our model automatically detected an additional 704 new brick kilns in\\nthe vicinity of the manually identified ones, as illustrated in the figure\\nA.4 Deployment 283\\nWe deploy a web application on Streamlit, as depicted in Figure 1, offering users an acces- 284\\nsible and interactive interface for brick kiln detection in a given area of interest. Once the 285\\nbounding box is defined, our model identifies brick kilns within this area and provides the 286\\ncoordinates of the brick kilns. Grad-CAM (Selvaraju et al., 2019) visuals accompany these 287\\non the original brick kiln image to highlight the areas where the model focuses. 288\\n11' metadata={'source': '/content/drive/MyDrive/Colab Notebooks/langchain/docs/NeurIPS23_Workshop_Accepted_BrickKilns.pdf', 'page': 10} \n",
            "\n",
            "\n",
            "page_content='(b)\\n (c)\\n (d)\\nFigure 1: Screenshots from our web application that help detect brick kilns (a) Selecting the\\ncoordinates of the bounding box (red rectangle) (b) Markers in the bounding box where the\\nmodel predicts the existence of a brick kiln (c) Statistics of number of brick kilns detected,\\ntheir coordinates and model’s predicted probabilities (d) Grad-CAM (Selvaraju et al., 2019)\\nvisual showing where our model focuses on predicted brick kiln image (Best viewed in color)\\n1. Introduction 14\\nAir pollution kills seven million people worldwide, and 22% of casualties are only from 15\\nIndia (UNEP, 2019). Annual average PM 2.5(Particulate matter of size ≤2.5µm) of 16\\nIndia was 24 µg/m3in 2020, which is significantly higher than the annual WHO limit 17\\nof 5 µg/m3(Guttikunda and Nishadh, 2022). Air quality researchers use physics-based 18\\nsimulators such as CAMx1to model the air quality (Guttikunda et al., 2019) using an 19\\ninventory of major sources. 20\\n1.https://www.camx.com/\\n1' metadata={'source': '/content/drive/MyDrive/Colab Notebooks/langchain/docs/NeurIPS23_Workshop_Accepted_BrickKilns.pdf', 'page': 0} \n",
            "\n",
            "\n",
            "page_content='maximise the information gained about the model parameters, i.e. maximise the mutual 97\\ninformation between predictions and model posterior.It is mathematically defined as: 98\\nI[y,θ|x,Dtrain] =H[y|x,Dtrain]−Ep(θ|Dtrain)[H[y|x,θ]]\\nwith θthe model parameters and H[y|x,θ] is the entropy of ygiven model weights θ. 99\\n3.Subset Scoring : We propose a new acquisition function to explicitly select the subset 100\\nof images classified as brick kilns in each iteration. The intuition is to select the points 101\\nthat are predicted as positive, but the model is not confident about them. Including 102\\nsuch points may boost model’s performance for the positive class especially in case of 103\\nclass imbalance. The function is defined as follows: 104\\nS[y|x,Dtrain] =I(ˆy=c)·α[y|x,Dtrain] (2)\\nwhere αcan be one of the acquisition functions discussed earlier. 105\\n4.Random : This acquisition function is equivalent to choosing an image uniformly at 106' metadata={'source': '/content/drive/MyDrive/Colab Notebooks/langchain/docs/NeurIPS23_Workshop_Accepted_BrickKilns.pdf', 'page': 3} \n",
            "\n",
            "\n",
            "page_content='•In our current work, we only looked at the binary classification task. Drawing inspiration 155\\nfrom (Lee et al., 2021), we plan to additionally localize the kilns in the image and extend 156\\nour active learning pipeline towards multiple objectives: localization and classification. 157\\n•Our current work treated the classification problem as a binary classification task. In the 158\\nfuture, we plan to study this formulation as a one-class task. Correspondingly, we also 159\\nplan to look at specialized losses such as the focal losses (Lin et al., 2017). 160\\n6. Conclusion 161\\nOur goal was to develop a scalable method to detect brick kilns. We conclude from our 162\\nresults that satellite data can be used to detect brick kilns accurately. Further, we conclude 163\\nthat we can develop accurate models by actively annotating images from the target region. 164\\nWe believe that our work will likely benefit key stakeholders such as scientists building 165' metadata={'source': '/content/drive/MyDrive/Colab Notebooks/langchain/docs/NeurIPS23_Workshop_Accepted_BrickKilns.pdf', 'page': 5} \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "top_docs = db_hf.similarity_search(query+base_answer, k=5)\n",
        "for i in top_docs:\n",
        "  print(i,\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "o1N4tdNG5dua"
      },
      "outputs": [],
      "source": [
        "chain = load_qa_chain(llm_mistral, chain_type=\"stuff\")\n",
        "response_hyde = chain.run(input_documents=top_docs, question=query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "teczWgzc6D2k",
        "outputId": "7df8ee0a-16f0-4411-8102-5f4905ebf6f1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\nWe show that using our methods, we need to annotate only a small number of images to 39\\nobtain brick kiln locations in a new region. On performing active learning on the Indian 40\\ndataset, we concluded that we needed 70% fewer samples than random to achieve a similar 41\\nF1 score. We also find that we could reach 97% of optimal F1 score with active learning, 42\\nwhereas random could reach only 90% with the same number of samples labeled. 43\\nFinally, we have developed a web application2offering users an accessible and interactive 44\\ninterface for brick kiln detection in a given region of interest. Figure 1 shows our web 45\\napplication which takes in bounding boxes of the area of interest and detects the kilns 46\\npresent in the region while also showing Grad-CAM (Selvaraju et al., 2019) visuals to 47\\nhighlight the focus area of the model. Our work is fully reproducible, and we intend to 48\\nrelease the scripts and data upon acceptance. 49\\n2. Dataset 50\\n\\n1000 images, and after manual inspection, we found 996 of them to be correctly classified. 281\\nThus through our approach we were able to reduce the annotation 282\\nBrick Kilns\\nIndia\\nFigure A: We initially manually located approximately 189 brick kilns in the Indo-Gangetic\\nplain. Subsequently, our model automatically detected an additional 704 new brick kilns in\\nthe vicinity of the manually identified ones, as illustrated in the figure\\nA.4 Deployment 283\\nWe deploy a web application on Streamlit, as depicted in Figure 1, offering users an acces- 284\\nsible and interactive interface for brick kiln detection in a given area of interest. Once the 285\\nbounding box is defined, our model identifies brick kilns within this area and provides the 286\\ncoordinates of the brick kilns. Grad-CAM (Selvaraju et al., 2019) visuals accompany these 287\\non the original brick kiln image to highlight the areas where the model focuses. 288\\n11\\n\\n(b)\\n (c)\\n (d)\\nFigure 1: Screenshots from our web application that help detect brick kilns (a) Selecting the\\ncoordinates of the bounding box (red rectangle) (b) Markers in the bounding box where the\\nmodel predicts the existence of a brick kiln (c) Statistics of number of brick kilns detected,\\ntheir coordinates and model’s predicted probabilities (d) Grad-CAM (Selvaraju et al., 2019)\\nvisual showing where our model focuses on predicted brick kiln image (Best viewed in color)\\n1. Introduction 14\\nAir pollution kills seven million people worldwide, and 22% of casualties are only from 15\\nIndia (UNEP, 2019). Annual average PM 2.5(Particulate matter of size ≤2.5µm) of 16\\nIndia was 24 µg/m3in 2020, which is significantly higher than the annual WHO limit 17\\nof 5 µg/m3(Guttikunda and Nishadh, 2022). Air quality researchers use physics-based 18\\nsimulators such as CAMx1to model the air quality (Guttikunda et al., 2019) using an 19\\ninventory of major sources. 20\\n1.https://www.camx.com/\\n1\\n\\nmaximise the information gained about the model parameters, i.e. maximise the mutual 97\\ninformation between predictions and model posterior.It is mathematically defined as: 98\\nI[y,θ|x,Dtrain] =H[y|x,Dtrain]−Ep(θ|Dtrain)[H[y|x,θ]]\\nwith θthe model parameters and H[y|x,θ] is the entropy of ygiven model weights θ. 99\\n3.Subset Scoring : We propose a new acquisition function to explicitly select the subset 100\\nof images classified as brick kilns in each iteration. The intuition is to select the points 101\\nthat are predicted as positive, but the model is not confident about them. Including 102\\nsuch points may boost model’s performance for the positive class especially in case of 103\\nclass imbalance. The function is defined as follows: 104\\nS[y|x,Dtrain] =I(ˆy=c)·α[y|x,Dtrain] (2)\\nwhere αcan be one of the acquisition functions discussed earlier. 105\\n4.Random : This acquisition function is equivalent to choosing an image uniformly at 106\\n\\n•In our current work, we only looked at the binary classification task. Drawing inspiration 155\\nfrom (Lee et al., 2021), we plan to additionally localize the kilns in the image and extend 156\\nour active learning pipeline towards multiple objectives: localization and classification. 157\\n•Our current work treated the classification problem as a binary classification task. In the 158\\nfuture, we plan to study this formulation as a one-class task. Correspondingly, we also 159\\nplan to look at specialized losses such as the focal losses (Lin et al., 2017). 160\\n6. Conclusion 161\\nOur goal was to develop a scalable method to detect brick kilns. We conclude from our 162\\nresults that satellite data can be used to detect brick kilns accurately. Further, we conclude 163\\nthat we can develop accurate models by actively annotating images from the target region. 164\\nWe believe that our work will likely benefit key stakeholders such as scientists building 165\\n\\nQuestion: What is performance of modele on detecting brick kilns\\nHelpful Answer: The model was able to reduce the annotation of brick kilns from 189 to 704 through active learning, achieving a similar F1 score with 70% fewer samples. The model was able to reach 97% of optimal F1 score with active learning, whereas random could reach only 90% with the same number of samples labeled. The model was also able to detect brick kilns in a new region with only a small number of annotated\""
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response_hyde"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deihk-Bs5drH",
        "outputId": "0d866bee-a10a-4067-cd64-8293d038b68b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What is performance of modele on detecting brick kilns\n",
            "Helpful Answer: The model was able to reduce the annotation of brick kilns from 189 to 704 through active learning, achieving a similar F1 score with 70% fewer samples. The model was able to reach 97% of optimal F1 score with active learning, whereas random could reach only 90% with the same number of samples labeled. The model was also able to detect brick kilns in a new region with only a small number of annotated\n"
          ]
        }
      ],
      "source": [
        "split_text = response_hyde.split(\"Question:\")\n",
        "question_part = split_text[1].split(\"Helpful Answer:\")\n",
        "\n",
        "question = question_part[0].strip()\n",
        "helpful_answer = question_part[1].strip()\n",
        "\n",
        "print(\"Question:\", question)\n",
        "print(\"Helpful Answer:\", helpful_answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5bOz61uc5dpB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
